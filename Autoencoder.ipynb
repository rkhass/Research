{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "\u001b[31m  Could not find a version that satisfies the requirement tensorflow (from versions: )\u001b[0m\n",
      "\u001b[31mNo matching distribution found for tensorflow\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (pywrap_tensorflow_internal.py, line 114)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2963\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-13-1e37359cbad8>\"\u001b[0m, line \u001b[1;32m3\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    import tensorflow as tf\n",
      "  File \u001b[1;32m\"/usr/local/lib/python3.7/site-packages/tensorflow/__init__.py\"\u001b[0m, line \u001b[1;32m22\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n",
      "  File \u001b[1;32m\"/usr/local/lib/python3.7/site-packages/tensorflow/python/__init__.py\"\u001b[0m, line \u001b[1;32m49\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    from tensorflow.python import pywrap_tensorflow\n",
      "\u001b[0;36m  File \u001b[0;32m\"/usr/local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\"\u001b[0;36m, line \u001b[0;32m58\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from tensorflow.python.pywrap_tensorflow_internal import *\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/usr/local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\"\u001b[0;36m, line \u001b[0;32m114\u001b[0m\n\u001b[0;31m    def TFE_ContextOptionsSetAsync(arg1, async):\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daten one hot kodieren für Modell 1\n",
    "df = pd.read_csv(\"Data/daten_anonym2/arzta_daten_anonym1.csv\", sep=';').iloc[:100, :]\n",
    "\n",
    "## transfrom str type to float type\n",
    "columns_comma = ['RECHNUNGSBETRAG', 'FAKTOR', 'BETRAG', 'ALTER', 'KORREKTUR'] \n",
    "df[columns_comma] = df[columns_comma].apply(lambda x: x.str.replace(',', '.'))\n",
    "for column in columns_comma:\n",
    "    df[column] = pd.to_numeric(df[column], downcast='float')\n",
    "    \n",
    "    \n",
    "# df1 = pd.get_dummies(df['NUMMER_KAT'])\n",
    "# df = df.drop(['NUMMER_KAT'], axis=1)\n",
    "# data = df.merge(df1, left_index=True, right_index=True)\n",
    "# df2 = pd.get_dummies(df['NUMMER'])\n",
    "# df = df.drop(['NUMMER'], axis=1)\n",
    "# data = data.merge(df2, left_index=True, right_index=True)\n",
    "# df3 = pd.get_dummies(df['LEISTUNG'])\n",
    "# df = df.drop(['LEISTUNG'], axis=1)\n",
    "# data = data.merge(df3, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Bag of Words\n",
    "unique = data.ID.value_counts(normalize=False).index.tolist()\n",
    "row_list = []\n",
    "row_list1 = []\n",
    "row_list2 = []\n",
    "row_list3 = []\n",
    "row_list4 = []\n",
    "row_list5 = []\n",
    "for i in unique:\n",
    "    unique1 = data[data['ID']==i]\n",
    "    df = unique1[['NUMMER', 'NUMMER_KAT', 'LEISTUNG']].astype(str)\n",
    "    neu = df.apply(lambda x: x.str.split(expand=True).stack()).stack().value_counts()\n",
    "    betr = unique1['RECHNUNGSBETRAG']\n",
    "    #betr = betr[0:1]\n",
    "    betr = betr.iloc[0]\n",
    "    alt = unique1['ALTER']\n",
    "    #alt = alt[1:2]\n",
    "    alt = alt.iloc[0]\n",
    "    gesch = unique1['GESCHLECHT']\n",
    "    #gesch = gesch[2:3]\n",
    "    gesch = gesch.iloc[0]\n",
    "    fach = unique1['FACHRICHTUNG']\n",
    "    #fach = fach[2:3]\n",
    "    fach = fach.iloc[0]\n",
    "    betrag = unique1['BETRAG']  \n",
    "    #betrag = betrag[12:13]\n",
    "    betrag = betrag.mean() ## !!!\n",
    "    row_list1.append(betr)\n",
    "    row_list2.append(alt)\n",
    "    row_list3.append(gesch)\n",
    "    row_list4.append(fach)\n",
    "    row_list5.append(betrag)\n",
    "    row_list.append(dict(neu))\n",
    "df3 = pd.DataFrame(row_list)\n",
    "df6 = pd.DataFrame(row_list1,columns=['RECHNUGSBETRAG'])\n",
    "df7 = pd.DataFrame(row_list2,columns=['ALTER'])\n",
    "df8 = pd.DataFrame(row_list3,columns=['GESCHLECHT'])\n",
    "df9 = pd.DataFrame(row_list5,columns=['BETRAG'])\n",
    "df10 = pd.DataFrame(row_list4,columns=['FACHRICHTUNG'])\n",
    "df4 = pd.DataFrame(unique, columns=['ID'])\n",
    "df5 = df4.merge(df6,left_index=True,right_index=True)\n",
    "df5 = df5.merge(df3,left_index=True,right_index=True)\n",
    "df5 = df5.merge(df7,left_index=True,right_index=True)\n",
    "df5 = df5.merge(df8,left_index=True,right_index=True)\n",
    "df5 = df5.merge(df9,left_index=True,right_index=True)\n",
    "df5 = df5.merge(df10,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-0b4b3f6d893a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtest1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m186\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtest4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LEISTUNG'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mtest1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m358\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mtest1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_setitem_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_tuple\u001b[0;34m(self, key, is_setter)\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Too many indexers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_setter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m                 \u001b[0mkeyidx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyidx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2120\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2121\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1955\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1957\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1958\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m             \u001b[0;31m# a tuple should already have been caught by this point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2007\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2009\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2011\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "#Aneinander hängen für Modell 2\n",
    "unique = data.ID.value_counts(normalize=False).index.tolist()\n",
    "leer = []\n",
    "for i in unique:\n",
    "    test1 = data[data['ID']==i]\n",
    "    for i in range(172):\n",
    "        i += 1\n",
    "        bez = 'NUMMER_KAT_' + str(i)\n",
    "        test1[bez] = np.nan\n",
    "        bez1 = 'NUMMER_' + str(i)\n",
    "        test1[bez1] = np.nan\n",
    "        bez2 = 'LEISTUNG_' + str(i)\n",
    "        test1[bez1] = np.nan\n",
    "    index = test1.index.values.astype(int)\n",
    "    for j in range(1,len(index)):\n",
    "        test2 = test1['NUMMER_KAT'][index[j]]\n",
    "        test1.iloc[0,14+j] = test2\n",
    "        test3 = test1['NUMMER'][index[j]]\n",
    "        test1.iloc[0,186+j] = test3\n",
    "        test4 = test1['LEISTUNG'][index[j]]\n",
    "        test1.iloc[0,358+j] = test3\n",
    "        k = index[j]\n",
    "        test1 = test1.drop(labels=k, axis = 0)\n",
    "    frames = [leer,test1,test2,test3]\n",
    "    leer = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('TransformedData.csv')\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:616: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:459: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['ID', 'target'], axis=1), df.target, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_x = scaler.fit_transform(X_train)\n",
    "test_x = scaler.transform(X_test)\n",
    "test_y = y_test\n",
    "train_y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.000 % sind Betrugsfälle \n",
      "     ID  RECHNUNGSBETRAG      ALTER  GESCHLECHT  VERSICHERUNG  FACHRICHTUNG  \\\n",
      "0  ID_1       330.970001  53.570385           0             1             1   \n",
      "1  ID_2       455.200012  83.382721           1             1             1   \n",
      "2  ID_3       199.529999  69.567513           1             1             1   \n",
      "3  ID_4       142.850006  69.556328           1             1             1   \n",
      "4  ID_5       168.869995  18.873434           0             1             1   \n",
      "\n",
      "   NUMMER NUMMER_KAT  TYP  ANZAHL  FAKTOR     BETRAG LEISTUNG  Betrug  \n",
      "0   A_178      AA_10  0.0       2    2.30  24.400000      C_1     0.0  \n",
      "1   A_765      AA_13  0.0       1    1.15   2.010000      C_6     0.0  \n",
      "2  A_1978       AA_2  0.0       1    2.30  21.450001      C_1     0.0  \n",
      "3  A_1257       AA_3  0.0       3    2.30  32.160000      C_1     0.0  \n",
      "4   A_737      AA_13  0.0       1    1.15   3.350000      C_6     0.0  \n",
      "[['ID_1' 330.9700012207031 53.57038497924805 0 1 1 'A_178' 'AA_10' 0.0 2\n",
      "  2.299999952316284 24.399999618530273 'C_1']\n",
      " ['ID_2' 455.20001220703125 83.38272094726562 1 1 1 'A_765' 'AA_13' 0.0 1\n",
      "  1.149999976158142 2.009999990463257 'C_6']\n",
      " ['ID_3' 199.52999877929688 69.56751251220703 1 1 1 'A_1978' 'AA_2' 0.0 1\n",
      "  2.299999952316284 21.450000762939453 'C_1']\n",
      " ['ID_4' 142.85000610351562 69.55632781982422 1 1 1 'A_1257' 'AA_3' 0.0 3\n",
      "  2.299999952316284 32.15999984741211 'C_1']\n",
      " ['ID_5' 168.8699951171875 18.87343406677246 0 1 1 'A_737' 'AA_13' 0.0 1\n",
      "  1.149999976158142 3.3499999046325684 'C_6']\n",
      " ['ID_6' 113.66000366210938 77.86614227294922 0 1 1 'A_719' 'AA_2' 0.0 1\n",
      "  2.299999952316284 40.22999954223633 'C_1']\n",
      " ['ID_7' 2775.2099609375 77.86614227294922 0 1 1 'A_1874' 'AA_15' 0.0 1\n",
      "  2.200000047683716 128.22999572753906 'C_5']\n",
      " ['ID_8' 41.77000045776367 66.94769287109375 1 1 1 nan 'AA_1' nan 1 0.0\n",
      "  0.699999988079071 'C_2']\n",
      " ['ID_9' 70.62999725341797 30.23857307434082 0 1 1 'A_1122' 'AA_13' 0.0 1\n",
      "  1.149999976158142 16.760000228881836 'C_6']\n",
      " ['ID_10' 104.9000015258789 52.904441833496094 0 1 1 'A_877' 'AA_13' 0.0\n",
      "  1 1.149999976158142 16.760000228881836 'C_6']\n",
      " ['ID_11' 443.0899963378906 80.62254333496094 1 1 1 'A_1978' 'AA_2' 0.0 1\n",
      "  2.299999952316284 21.450000762939453 'C_1']\n",
      " ['ID_12' 328.0400085449219 77.69287109375 1 0 0 'A_1650' 'AA_4' 0.0 1\n",
      "  2.299999952316284 16.219999313354492 'C_20']\n",
      " ['ID_13' 82.9800033569336 43.64557647705078 1 1 1 nan 'AA_1' nan 1 0.0\n",
      "  5.5 'C_2']\n",
      " ['ID_14' 77.08999633789062 70.25144958496094 1 1 1 'A_796' 'AA_13' 0.0 1\n",
      "  1.149999976158142 2.680000066757202 'C_6']\n",
      " ['ID_15' 151.49000549316406 64.76517486572266 0 1 1 'A_178' 'AA_10' 0.0\n",
      "  1 2.299999952316284 12.199999809265137 'C_1']\n",
      " ['ID_16' 399.8299865722656 75.13312530517578 1 1 1 'A_620' 'AA_3' 0.0 1\n",
      "  2.299999952316284 12.050000190734863 'C_1']\n",
      " ['ID_17' 203.27000427246094 38.54792404174805 1 1 1 'A_767' 'AA_13' 0.0\n",
      "  1 1.149999976158142 2.680000066757202 'C_6']\n",
      " ['ID_18' 1028.3800048828125 58.7855110168457 0 1 1 'A_783' 'AA_13' 0.0 1\n",
      "  1.149999976158142 2.680000066757202 'C_6']\n",
      " ['ID_19' 774.989990234375 83.93265533447266 0 1 1 'A_1852' 'AA_15' 0.0 1\n",
      "  2.5 612.02001953125 'C_4']\n",
      " ['ID_20' 296.92999267578125 80.2723388671875 0 1 1 'A_791' 'AA_13' 0.0 1\n",
      "  1.149999976158142 2.680000066757202 'C_6']\n",
      " ['ID_21' 107.68000030517578 59.510982513427734 0 1 1 'A_749' 'AA_13' 0.0\n",
      "  1 1.149999976158142 6.699999809265137 'C_6']\n",
      " ['ID_22' 1758.8499755859375 76.61495208740234 1 1 1 'A_1978' 'AA_2' 0.0\n",
      "  1 2.299999952316284 21.450000762939453 'C_1']\n",
      " ['ID_23' 93.87000274658203 75.63273620605469 0 1 1 'A_1517' 'AA_13' 0.0\n",
      "  1 1.149999976158142 38.209999084472656 'C_6']\n",
      " ['ID_24' 414.4800109863281 41.64663314819336 0 1 1 nan 'AA_1' nan 1 0.0\n",
      "  4.75 'C_2']\n",
      " ['ID_25' 386.7699890136719 64.43936920166016 1 1 1 'A_1129' 'AA_13' 0.0\n",
      "  1 1.149999976158142 16.760000228881836 'C_6']\n",
      " ['ID_26' 291.54998779296875 63.50810623168945 1 1 1 'A_178' 'AA_10' 0.0\n",
      "  1 2.299999952316284 12.199999809265137 'C_20']\n",
      " ['ID_27' 487.6400146484375 81.3892593383789 1 1 1 'A_1' 'AA_2' 0.0 1\n",
      "  2.299999952316284 10.720000267028809 'C_1']\n",
      " ['ID_28' 172.7899932861328 66.73619079589844 1 1 1 'A_1649' 'AA_4' 0.0 2\n",
      "  2.299999952316284 16.360000610351562 'C_20']\n",
      " ['ID_29' 7.03000020980835 76.83380126953125 0 1 1 'A_852' 'AA_13' 0.0 1\n",
      "  1.149999976158142 2.680000066757202 'C_6']\n",
      " ['ID_30' 252.49000549316406 88.0948257446289 1 1 1 'A_918' 'AA_13' 0.0 1\n",
      "  1.149999976158142 13.40999984741211 'C_6']\n",
      " ['ID_31' 462.760009765625 62.44026184082031 1 1 1 'A_545' 'AA_3' 0.0 1\n",
      "  1.7999999523162842 4.199999809265137 'C_1']\n",
      " ['ID_32' 124.0199966430664 62.44026184082031 1 1 1 nan 'AA_1' nan 1 0.0\n",
      "  5.369999885559082 'C_2']\n",
      " ['ID_33' 473.3900146484375 87.64783477783203 0 1 1 'A_769' 'AA_13' 0.0 1\n",
      "  1.149999976158142 2.680000066757202 'C_6']\n",
      " ['ID_34' 142.85000610351562 70.58299255371094 1 1 1 'A_1' 'AA_2' 0.0 1\n",
      "  2.299999952316284 10.720000267028809 'C_1']\n",
      " ['ID_35' 248.9600067138672 76.98667907714844 0 1 1 'A_1257' 'AA_3' 0.0 1\n",
      "  2.299999952316284 10.720000267028809 'C_1']\n",
      " ['ID_36' 52.349998474121094 66.1613540649414 1 1 1 nan 'AA_1' nan 1 0.0\n",
      "  6.099999904632568 'C_2']\n",
      " ['ID_37' 209.82000732421875 49.734107971191406 1 1 1 'A_1890' 'AA_6' 0.0\n",
      "  1 1.7999999523162842 15.949999809265137 'C_1']\n",
      " ['ID_38' 206.19000244140625 4.497043132781982 0 1 1 'A_57' 'AA_9' 0.0 1\n",
      "  2.299999952316284 11.930000305175781 'C_1']\n",
      " ['ID_39' 135.02999877929688 82.88743591308594 0 1 1 'A_68' 'AA_9' 0.0 1\n",
      "  2.299999952316284 12.199999809265137 'C_1']\n",
      " ['ID_40' 605.510009765625 72.79020690917969 1 1 1 'A_1780' 'AA_15' 0.0 1\n",
      "  2.200000047683716 333.3999938964844 'C_4']\n",
      " ['ID_41' 193.77999877929688 82.88743591308594 0 1 1 'A_1' 'AA_2' 0.0 1\n",
      "  2.299999952316284 10.720000267028809 'C_1']\n",
      " ['ID_42' 378.4800109863281 34.6402587890625 1 1 1 'A_586' 'AA_3' 0.0 1\n",
      "  2.299999952316284 17.43000030517578 'C_1']\n",
      " ['ID_43' 159.83999633789062 82.88743591308594 0 1 1 'A_818' 'AA_13' 0.0\n",
      "  1 1.149999976158142 3.3499999046325684 'C_6']\n",
      " ['ID_44' 98.3499984741211 74.53628540039062 0 1 1 'A_1737' 'AA_15' 0.0 1\n",
      "  1.0 6.559999942779541 'C_4']\n",
      " ['ID_45' 216.82000732421875 72.1358413696289 1 1 1 'A_1650' 'AA_4' 0.0 1\n",
      "  2.299999952316284 16.219999313354492 'C_20']\n",
      " ['ID_46' 107.0 68.17916107177734 0 1 1 'A_759' 'AA_13' 0.0 1\n",
      "  1.149999976158142 4.019999980926514 'C_6']\n",
      " ['ID_47' 64.80999755859375 13.488341331481934 1 1 1 'A_1' 'AA_2' 0.0 1\n",
      "  2.299999952316284 10.720000267028809 'C_1']\n",
      " ['ID_48' 17.329999923706055 36.63166046142578 1 1 1 nan 'AA_1' nan 1 0.0\n",
      "  3.9200000762939453 'C_2']\n",
      " ['ID_49' 92.25 79.31682586669922 0 1 1 'A_1014' 'AA_13' 0.0 1\n",
      "  1.149999976158142 20.110000610351562 'C_6']\n",
      " ['ID_50' 135.75 68.348876953125 0 1 1 'A_1257' 'AA_3' 0.0 3 3.5\n",
      "  48.959999084472656 'C_1']\n",
      " ['ID_51' 359.2099914550781 81.44963073730469 0 1 1 'A_778' 'AA_13' 0.0 1\n",
      "  1.149999976158142 13.40999984741211 'C_6']\n",
      " ['ID_52' 311.57000732421875 49.734107971191406 1 1 1 nan 'AA_1' nan 1\n",
      "  0.0 1.5 'C_21']\n",
      " ['ID_53' 865.1300048828125 44.010128021240234 1 1 1 'A_1' 'AA_2' 0.0 1\n",
      "  2.299999952316284 10.720000267028809 'C_1']\n",
      " ['ID_52' 311.57000732421875 49.734107971191406 1 1 1 nan 'AA_1' nan 1\n",
      "  0.0 0.8399999737739563 'C_21']\n",
      " ['ID_54' 411.8599853515625 33.74595260620117 1 1 1 'A_1' 'AA_2' 0.0 1\n",
      "  3.5 16.31999969482422 'C_1']\n",
      " ['ID_55' 468.0899963378906 72.97837829589844 1 1 1 'A_1937' 'AA_6' 0.0 1\n",
      "  1.7999999523162842 26.540000915527344 'C_1']\n",
      " ['ID_56' 271.2099914550781 79.81248474121094 1 1 1 'A_2001' 'AA_2' 0.0 1\n",
      "  1.7999999523162842 13.640000343322754 'C_1']\n",
      " ['ID_57' 17.329999923706055 64.8004379272461 0 1 1 nan 'AA_1' nan 1 0.0\n",
      "  3.9200000762939453 'C_2']\n",
      " ['ID_58' 260.2799987792969 75.09790802001953 0 1 1 'A_2190' 'AA_1' 0.0 1\n",
      "  1.0 9.329999923706055 'C_1']\n",
      " ['ID_59' 20.68000030517578 74.6604232788086 1 1 1 'A_1129' 'AA_13' 0.0 1\n",
      "  1.149999976158142 16.760000228881836 'C_6']\n",
      " ['ID_60' 662.2000122070312 69.56751251220703 1 1 1 'A_727' 'AA_13' 0.0 1\n",
      "  1.2999999523162842 4.550000190734863 'C_6']\n",
      " ['ID_61' 220.64999389648438 70.08216857910156 1 1 1 'A_737' 'AA_13' 0.0\n",
      "  1 1.149999976158142 3.3499999046325684 'C_6']\n",
      " ['ID_62' 173.02999877929688 82.15094757080078 0 1 1 'A_644' 'AA_3' 0.0 2\n",
      "  2.299999952316284 10.720000267028809 'C_1']\n",
      " ['ID_63' 115.12000274658203 0.31615903973579407 0 1 1 'A_885' 'AA_3' 0.0\n",
      "  1 2.5 11.65999984741211 'C_3']\n",
      " ['ID_64' 522.97998046875 68.01184844970703 1 1 1 'A_876' 'AA_13' 0.0 1\n",
      "  1.149999976158142 13.40999984741211 'C_6']\n",
      " ['ID_65' 286.4700012207031 66.74187469482422 1 1 1 'A_645' 'AA_2' 0.0 1\n",
      "  2.299999952316284 20.100000381469727 'C_1']\n",
      " ['ID_66' 369.8500061035156 47.09215545654297 1 1 1 'A_2030' 'AA_7' 0.0 1\n",
      "  2.299999952316284 26.139999389648438 'C_1']\n",
      " ['ID_67' 275.6099853515625 65.55116271972656 1 1 1 'A_545' 'AA_3' 0.0 1\n",
      "  1.7999999523162842 4.199999809265137 'C_1']\n",
      " ['ID_68' 439.3299865722656 81.63862609863281 1 1 1 'A_768' 'AA_13' 0.0 1\n",
      "  1.149999976158142 13.40999984741211 'C_6']\n",
      " ['ID_69' 109.5 67.84801483154297 0 1 1 'A_784' 'AA_13' 0.0 1\n",
      "  1.149999976158142 2.680000066757202 'C_6']\n",
      " ['ID_70' 52.060001373291016 56.76217269897461 1 1 1 'A_1656' 'AA_2' 0.0\n",
      "  1 2.299999952316284 10.720000267028809 'C_1']\n",
      " ['ID_71' 37.189998626708984 73.49356079101562 1 1 1 'A_1' 'AA_2' 0.0 1\n",
      "  2.299999952316284 10.720000267028809 'C_1']\n",
      " ['ID_72' 387.010009765625 69.4033432006836 1 1 1 'A_764' 'AA_13' 0.0 1\n",
      "  1.149999976158142 2.009999990463257 'C_6']\n",
      " ['ID_73' 76.8499984741211 68.10259246826172 0 1 1 'A_1' 'AA_2' 0.0 1\n",
      "  2.299999952316284 10.720000267028809 'C_1']\n",
      " ['ID_74' 1148.8699951171875 60.06147384643555 1 1 1 'A_1890' 'AA_6' 0.0\n",
      "  1 1.7999999523162842 15.949999809265137 'C_1']]\n",
      "Größe Trainingssatz 75, Anzahl Betrug: 1.0, Prozentualer Anteil Betrug 0.01333\n",
      "Größe Testsatz 25, Anzahl Betrug: 1.0, Prozentualer Anteil Betrug 0.04000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-f2340462ea9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mstd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "'''Spalte Betrug einfügen; 0-> kein Betrug, 1 -> Betrug'''\n",
    "df.loc [ df.KORREKTUR > 0 , 'Betrug' ] = 1\n",
    "df.loc [ df.KORREKTUR == 0 , 'Betrug' ] = 0\n",
    "df = df.drop(['KORREKTUR'],axis=1)\n",
    "df = df.drop(['ART'],axis=1)\n",
    "print(\"{:.3f} % sind Betrugsfälle \".format(np.sum(df['Betrug']) / df.shape[0] * 100))\n",
    "print(df.head())\n",
    "\n",
    "#%%\n",
    "'''Datensatz aufteilen, so dass in beiden der gleich Anteil Betrug vorkommt'''\n",
    "split = 0.25\n",
    "anteil_trainingssatz = int((1-split) *df.shape[0])\n",
    "train_x = df.iloc[:anteil_trainingssatz, 0:-1].values\n",
    "train_y = df.iloc[:anteil_trainingssatz, -1].values\n",
    "test_x = df.iloc[anteil_trainingssatz:, 0:-1].values\n",
    "test_y = df.iloc[anteil_trainingssatz:, -1].values\n",
    "\n",
    "print(train_x)\n",
    "print(\"Größe Trainingssatz {}, Anzahl Betrug: {}, Prozentualer Anteil Betrug {:.5f}\".format(train_x.shape[0], np.sum(train_y), np.sum(train_y)/train_x.shape[0]))\n",
    "print(\"Größe Testsatz {}, Anzahl Betrug: {}, Prozentualer Anteil Betrug {:.5f}\".format(test_x.shape[0], np.sum(test_y), np.sum(test_y)/test_y.shape[0]))\n",
    "\n",
    "#%%\n",
    "'''Normalisierung'''\n",
    "mean = []\n",
    "std = []\n",
    "for i in range(train_x.shape[1]):\n",
    "    mean.append(train_x[:,i].mean())\n",
    "    std.append(train_x[:,i].std())\n",
    "    train_x[:, i] = (train_x[:, i] - mean[-1]) / std[-1]\n",
    "    test_x[:, i] =  (test_x[:, i] - mean[-1]) / std[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%%\n",
    "ausgabe_zaehler = 1\n",
    "\n",
    "'''Hyperparameter'''\n",
    "lernrate = 0.001\n",
    "epochen = 1000\n",
    "batch = 1024\n",
    "beta = 0.1\n",
    "momentum = 0.2\n",
    "#%%\n",
    "'''Knoten in versteckter Schicht'''\n",
    "n_hidden_1 = 15 #Knoten in erster Schicht\n",
    "n_hidden_2 = 10 #Knoten in zweiter Schicht\n",
    "n_hidden_3 = 5  #Knoten in dritter Schicht\n",
    "\n",
    "'''Inputschicht'''\n",
    "n_input = train_x.shape[1]\n",
    "\n",
    "#%%\n",
    "'''Platzhalter für Tensor'''\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "\n",
    "'''Gewichte - zufällig Standardnormal'''\n",
    "gewicht = {\n",
    "        'encoder_h1': tf.Variable(tf.random_normal([n_input , n_hidden_1])),\n",
    "        'decoder_h1': tf.Variable(tf.random_normal([n_hidden_1, n_input])),\n",
    "        'encoder_h2': tf.Variable(tf.random_normal([n_hidden_1 , n_hidden_2])),\n",
    "        'decoder_h2': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_1])),\n",
    "        'encoder_h3': tf.Variable(tf.random_normal([n_hidden_2 , n_hidden_3])),\n",
    "        'decoder_h3': tf.Variable(tf.random_normal([n_hidden_3 , n_hidden_2]))\n",
    "        }\n",
    "\n",
    "'''Bias - zufällig Standardnormal'''\n",
    "bias = {\n",
    "        'encoder_b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "        'decoder_b1': tf.Variable(tf.random_normal([n_input])),\n",
    "        'encoder_b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "        'decoder_b2': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "        'encoder_b3': tf.Variable(tf.random_normal([n_hidden_3])),\n",
    "        'decoder_b3': tf.Variable(tf.random_normal([n_hidden_2]))\n",
    "        }\n",
    "\n",
    "#%%\n",
    "'''Encoder'''\n",
    "def encoder(x):\n",
    "    # erste Schicht\n",
    "    layer_1 = tf.nn.tanh(tf.add(tf.matmul(x, gewicht['encoder_h1']), bias['encoder_b1']))\n",
    "    # dropout mit Rate pi\n",
    "    layer_1 = tf.layers.dropout(layer_1,rate=0.2)\n",
    "    # zweite Schicht\n",
    "    layer_2 = tf.nn.tanh(tf.add(tf.matmul(layer_1, gewicht['encoder_h2']), bias['encoder_b2']))\n",
    "    # dropout mit Rate pi\n",
    "    layer_2 = tf.layers.dropout(layer_2,rate=0.2)\n",
    "    # dritte Schicht\n",
    "    layer_3 = tf.nn.tanh(tf.add(tf.matmul(layer_2, gewicht['encoder_h3']), bias['encoder_b3']))\n",
    "    # dropout mit Rate pi\n",
    "    layer_3 = tf.layers.dropout(layer_3,rate=0.2)\n",
    "    return layer_3\n",
    "\n",
    "\n",
    "#%%\n",
    "'''Decoder'''\n",
    "def decoder(x):\n",
    "    # erste Schicht\n",
    "    layer_1 = tf.nn.tanh(tf.add(tf.matmul(x, gewicht['decoder_h3']), bias['decoder_b3']))\n",
    "    # dropout mit Rate pi\n",
    "    layer_1 = tf.layers.dropout(layer_1,rate=0.2)\n",
    "    # zweite Schicht\n",
    "    layer_2 = tf.nn.tanh(tf.add(tf.matmul(layer_1, gewicht['decoder_h2']), bias['decoder_b2']))\n",
    "    # dropout mit Rate pi\n",
    "    layer_2 = tf.layers.dropout(layer_2,rate=0.2)\n",
    "    # dritte Schicht\n",
    "    layer_3 = tf.nn.tanh(tf.add(tf.matmul(layer_2, gewicht['decoder_h1']), bias['decoder_b1']))\n",
    "    # dropout mit Rate pi\n",
    "    layer_3 = tf.layers.dropout(layer_3,rate=0.2)\n",
    "    return layer_3\n",
    "\n",
    "#%%\n",
    "'''Autoencoder'''\n",
    "encoder_op = encoder(X)\n",
    "decoder_op = decoder(encoder_op)\n",
    "\n",
    "#%%\n",
    "'''Output Autoencoder'''\n",
    "y_pred = decoder_op\n",
    "\n",
    "#%%\n",
    "'''gewünschter Output = Input'''\n",
    "y_true = X\n",
    "\n",
    "#%%\n",
    "'''mittlerer quadratischer Fehler im batch'''\n",
    "batch_mse = tf.reduce_mean(tf.pow(y_true - y_pred, 2), 1)\n",
    "\n",
    "#%%\n",
    "'''Fehlerfunktion'''\n",
    "fehler = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
    "\n",
    "'''Opitimierer'''\n",
    "#Standardotimierer\n",
    "optimierer = tf.train.RMSPropOptimizer(lernrate).minimize(fehler)\n",
    "\n",
    "#Momentumoptimierer\n",
    "#optimizer = tf.train.MomentumOptimizer(lernrate,momentum).minimize(fehler)\n",
    "\n",
    "'''Regularisierung'''\n",
    "#L2 Regularisierungsterm\n",
    "reg = tf.nn.l2_loss(gewicht['encoder_h1']) + tf.nn.l2_loss(gewicht['encoder_h2']) + tf.nn.l2_loss(gewicht['decoder_h1']) + tf.nn.l2_loss(gewicht['decoder_h2'])\n",
    "#reg = tf.nn.l2_loss(gewicht['encoder_h1']) + tf.nn.l2_loss(gewicht['encoder_h2']) + tf.nn.l2_loss(gewicht['decoder_h1']) + tf.nn.l2_loss(gewicht['decoder_h2']) + tf.nn.l2_loss(gewicht['decoder_h3']) + tf.nn.l2_loss(gewicht['decoder_h3'])\n",
    "\n",
    "#Fehlerfunktion mit L2 Regularisierung\n",
    "fehler = tf.reduce_mean(fehler + beta * reg)\n",
    "#%%\n",
    "'''Modell speichern'''\n",
    "pfad = '.'\n",
    "save_model = os.path.join(pfad, 'temp_modell.ckpt')\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "#%%\n",
    "'''Variablen initialisieren'''\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "'''Session starten'''\n",
    "with tf.Session() as sess:\n",
    "    now = datetime.now()\n",
    "    sess.run(init)\n",
    "    total_batch = int(train_x.shape[0]/batch)\n",
    "    #Trainingsepochen\n",
    "    for epoche in range(epochen):\n",
    "        #Schleife über alle batches\n",
    "        for i in range(total_batch):\n",
    "            #batch ziehen\n",
    "            batch_idx = np.random.choice(train_x.shape[0], batch)\n",
    "            batch_xs = train_x[batch_idx]\n",
    "            #optimieren\n",
    "            _, Fehler = sess.run([optimierer, fehler], feed_dict={X: batch_xs})\n",
    "        # Display logs per epoch step\n",
    "        if epoche % ausgabe_zaehler == 0:\n",
    "            train_batch_mse = sess.run(batch_mse, feed_dict={X: train_x})\n",
    "            print(\"Epoche:\", '%04d' % (epoche+1),\n",
    "                  \"Fehler =\", \"{:.9f}\".format(Fehler),\n",
    "                  \"Trainings-AUC =\", \"{:.6f}\".format(auc(train_y, train_batch_mse)),\n",
    "                  \"Zeit =\", \"{}\".format(datetime.now() - now))\n",
    "    save_path = saver.save(sess, save_model)\n",
    "    print(\"Fertig %s\" % save_path)\n",
    "\n",
    "#%%\n",
    "'''Modell auf Testdatensatz testen'''\n",
    "save_model = os.path.join(pfad, 'temp_modell.ckpt')\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    now = datetime.now()\n",
    "    saver.restore(sess, save_model)\n",
    "    test_batch_mse = sess.run(batch_mse, feed_dict={X: test_x})\n",
    "    print(\"Test-AUC: {:.6f}\".format(auc(test_y, test_batch_mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
